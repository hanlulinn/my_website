---
categories:
- ""
- ""
date: "2017-10-31T22:42:51-05:00"
description: Nullam et orci eu lorem consequat tincidunt vivamus et sagittis magna
  sed nunc rhoncus condimentum sem. In efficitur ligula tate urna. Maecenas massa
  sed magna lacinia magna pellentesque lorem ipsum dolor. Nullam et orci eu lorem
  consequat tincidunt. Vivamus et sagittis tempus.
draft: false
image: pic07.jpg
keywords: ""
slug: hanlulin
title: Aliquam
---

<script src="Hanlu Lin_files/header-attrs/header-attrs.js"></script>


<p>The goal is to test your software installation, to demonstrate competency in Markdown, and in the basics of <code>ggplot</code>.</p>
<div id="task-1-short-biography-written-using-markdown" class="section level1">
<h1>Task 1: Short biography written using markdown</h1>
<div id="brief-biography" class="section level2">
<h2>Brief Biography</h2>
<p>My name is <strong>Hanlu Lin</strong>. I was born in China, Fujian province, lying in the southeastern part of China. I studied in <em>Fuzhou No.1 High school</em> in Fuzhou, and then studied my bachelor degree in <em>Hong Kong</em>, majoring in Hotel Management and Finance.</p>
<p>Before I applied to London Business School for the MAM program, I have several internship experience as follows:<br />
1. Business Analyst in <a href="https://www.tencent.com/en-us">Tencent</a><br />
2. Strategic Consultant in <a href="https://www.kantar.com/expertise/consulting">Kantar Consulting</a><br />
3. Analyst in <a href="https://internationalresidential.jll.com.hk/">Jones Lang LaSalle</a></p>
<p>From the internship experience, I decided to dig deeper into the business analytics fields. And I applied for the master degree in <strong>London Business School</strong>, which is a renowned business school with such beautiful campus <img src="http://prod-upp-image-read.ft.com/e161f29e-cf1d-11e7-b781-794ce08b24dc" alt="campus" /> located in London.I very much look forward to my study life there in London Business School for the coming years.</p>
</div>
</div>
<div id="task-2-gapminder-country-comparison" class="section level1">
<h1>Task 2: <code>gapminder</code> country comparison</h1>
<pre class="r"><code>glimpse(gapminder)</code></pre>
<pre><code>## Rows: 1,704
## Columns: 6
## $ country   &lt;fct&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, ~
## $ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, ~
## $ year      &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, ~
## $ lifeExp   &lt;dbl&gt; 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.854, 40.8~
## $ pop       &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 12~
## $ gdpPercap &lt;dbl&gt; 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 786.1134, ~</code></pre>
<pre class="r"><code>head(gapminder, 20) # look at the first 20 rows of the dataframe</code></pre>
<pre><code>## # A tibble: 20 x 6
##    country     continent  year lifeExp      pop gdpPercap
##    &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;
##  1 Afghanistan Asia       1952    28.8  8425333      779.
##  2 Afghanistan Asia       1957    30.3  9240934      821.
##  3 Afghanistan Asia       1962    32.0 10267083      853.
##  4 Afghanistan Asia       1967    34.0 11537966      836.
##  5 Afghanistan Asia       1972    36.1 13079460      740.
##  6 Afghanistan Asia       1977    38.4 14880372      786.
##  7 Afghanistan Asia       1982    39.9 12881816      978.
##  8 Afghanistan Asia       1987    40.8 13867957      852.
##  9 Afghanistan Asia       1992    41.7 16317921      649.
## 10 Afghanistan Asia       1997    41.8 22227415      635.
## 11 Afghanistan Asia       2002    42.1 25268405      727.
## 12 Afghanistan Asia       2007    43.8 31889923      975.
## 13 Albania     Europe     1952    55.2  1282697     1601.
## 14 Albania     Europe     1957    59.3  1476505     1942.
## 15 Albania     Europe     1962    64.8  1728137     2313.
## 16 Albania     Europe     1967    66.2  1984060     2760.
## 17 Albania     Europe     1972    67.7  2263554     3313.
## 18 Albania     Europe     1977    68.9  2509048     3533.
## 19 Albania     Europe     1982    70.4  2780097     3631.
## 20 Albania     Europe     1987    72    3075321     3739.</code></pre>
<pre class="r"><code>country_data &lt;- gapminder %&gt;% 
            filter(country == &quot;China&quot;) 

continent_data &lt;- gapminder %&gt;% 
            filter(continent == &quot;Asia&quot;)</code></pre>
<pre class="r"><code>plot1 &lt;- ggplot(data = country_data, mapping = aes(x = year, y = lifeExp))+
   geom_point() +
   geom_smooth(se = FALSE)+
   NULL 

plot1</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/blogs/Hanlu%20Lin_files/figure-html/lifeExp_one_country-1.png" width="672" /></p>
<pre class="r"><code>plot1&lt;- plot1 +
  labs(title = &quot;China&#39;s life expectancy over time&quot;,
      x = &quot;Year&quot;,
      y = &quot;Life Expectancy&quot;) +
  NULL


plot1</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/blogs/Hanlu%20Lin_files/figure-html/lifeExp_one_country_with_label-1.png" width="672" /></p>
<pre class="r"><code>ggplot(continent_data, mapping = aes(x = year, y = lifeExp, colour= country, group = country))+
  geom_point() + 
  geom_smooth(se = FALSE) +
  NULL</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/blogs/Hanlu%20Lin_files/figure-html/lifeExp_one_continent-1.png" width="672" /></p>
<pre class="r"><code>ggplot(data = gapminder , mapping = aes(x = year, y = lifeExp,colour = continent))+
  geom_point() + 
  geom_smooth(se = FALSE) +
  facet_wrap(~continent) +
  theme(legend.position=&quot;none&quot;) + #remove all legends
  NULL</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/blogs/Hanlu%20Lin_files/figure-html/lifeExp_facet_by_continent-1.png" width="672" /></p>
<blockquote>
<p>Type your answer after this blockquote.</p>
</blockquote>
<p>Given these trends, we can find that most of the countries in Asia, including China, have a stable increase of life expectancy since 1952. And there shows a slowdown in the growth of life expectancy in Asian countries from 1980. Among all continents, all of the 5 continents shows growth in life expectancy over years from 1951. The growth rate of life expectancy in Asia is higher than that in continents like Afria, Europe and Oceania. So that we can tell that the development of economics,culture and medical treatement in those develeoping countries in Asia since 1952 is in a more rapid pace, comparing to those developed countries in Europe.</p>
</div>
<div id="task-3-brexit-vote-analysis" class="section level1">
<h1>Task 3: Brexit vote analysis</h1>
<pre class="r"><code>brexit_results &lt;- read_csv(here::here(&quot;brexit_results.csv&quot;))


glimpse(brexit_results)</code></pre>
<pre><code>## Rows: 632
## Columns: 11
## $ Seat        &lt;chr&gt; &quot;Aldershot&quot;, &quot;Aldridge-Brownhills&quot;, &quot;Altrincham and Sale W~
## $ con_2015    &lt;dbl&gt; 50.592, 52.050, 52.994, 43.979, 60.788, 22.418, 52.454, 22~
## $ lab_2015    &lt;dbl&gt; 18.333, 22.369, 26.686, 34.781, 11.197, 41.022, 18.441, 49~
## $ ld_2015     &lt;dbl&gt; 8.824, 3.367, 8.383, 2.975, 7.192, 14.828, 5.984, 2.423, 1~
## $ ukip_2015   &lt;dbl&gt; 17.867, 19.624, 8.011, 15.887, 14.438, 21.409, 18.821, 21.~
## $ leave_share &lt;dbl&gt; 57.89777, 67.79635, 38.58780, 65.29912, 49.70111, 70.47289~
## $ born_in_uk  &lt;dbl&gt; 83.10464, 96.12207, 90.48566, 97.30437, 93.33793, 96.96214~
## $ male        &lt;dbl&gt; 49.89896, 48.92951, 48.90621, 49.21657, 48.00189, 49.17185~
## $ unemployed  &lt;dbl&gt; 3.637000, 4.553607, 3.039963, 4.261173, 2.468100, 4.742731~
## $ degree      &lt;dbl&gt; 13.870661, 9.974114, 28.600135, 9.336294, 18.775591, 6.085~
## $ age_18to24  &lt;dbl&gt; 9.406093, 7.325850, 6.437453, 7.747801, 5.734730, 8.209863~</code></pre>
<pre class="r"><code># histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_histogram(binwidth = 2.5)+
  labs(title = &quot;Distribution of constituencies&#39; leave share&quot;,
      x = &quot;Leave Share&quot;,
      y = &quot;Count&quot;)</code></pre>
<p><img src="/blogs/Hanlu%20Lin_files/figure-html/brexit_histogram-1.png" width="672" /></p>
<pre class="r"><code># density plot-- think smoothed histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_density()+
  labs(title = &quot;Density of constituencies&#39; leave share&quot;,
      x = &quot;Leave Share&quot;,
      y = &quot;Density&quot;)</code></pre>
<p><img src="/blogs/Hanlu%20Lin_files/figure-html/brexit_histogram-2.png" width="672" /></p>
<pre class="r"><code># The empirical cumulative distribution function (ECDF) 
ggplot(brexit_results, aes(x = leave_share)) +
  stat_ecdf(geom = &quot;step&quot;, pad = FALSE) +
  scale_y_continuous(labels = scales::percent)+
  labs(title = &quot;Empirical cumulative distribution of constituencies&#39; leave share&quot;,
      x = &quot;Leave Share&quot;,
      y = &quot;Cumulative distribution&quot;)</code></pre>
<p><img src="/blogs/Hanlu%20Lin_files/figure-html/brexit_histogram-3.png" width="672" /></p>
<pre class="r"><code>brexit_results %&gt;% 
  select(leave_share, born_in_uk) %&gt;% 
  cor()</code></pre>
<pre><code>##             leave_share born_in_uk
## leave_share   1.0000000  0.4934295
## born_in_uk    0.4934295  1.0000000</code></pre>
<pre class="r"><code>ggplot(brexit_results, aes(x = born_in_uk, y = leave_share)) +
  geom_point(alpha=0.3) +
  
  # add a smoothing line, and use method=&quot;lm&quot; to get the best straight-line
  geom_smooth(method = &quot;lm&quot;) + 
  
  # use a white background and frame the plot with a black box
  theme_bw() +
  
  labs(title = &quot;Correlation between the proportion of native born residents in a constituency and its leave share&quot;,
      x = &quot;Proportion of native born residents&quot;,
      y = &quot;Leave Share&quot;)+
  
  NULL</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="/blogs/Hanlu%20Lin_files/figure-html/brexit_immigration_plot-1.png" width="672" /></p>
<blockquote>
<p>Type your answer after, and outside, this blockquote.</p>
</blockquote>
<p>My analysis shows that the proportion of native born residents in a constituency and its leave share are positively correlated. With more proportion of native born residents in the constituency, the leave share of the constituency is higher, which is to say, in those constituencies that containing more natives, people are more tend to support the Brexit, with the fear of immigration and opposition to the EU’s more open border policy.</p>
</div>
<div id="task-4-animal-rescue-incidents-attended-by-the-london-fire-brigade" class="section level1">
<h1>Task 4: Animal rescue incidents attended by the London Fire Brigade</h1>
<pre class="r"><code>url &lt;- &quot;https://data.london.gov.uk/download/animal-rescue-incidents-attended-by-lfb/8a7d91c2-9aec-4bde-937a-3998f4717cd8/Animal%20Rescue%20incidents%20attended%20by%20LFB%20from%20Jan%202009.csv&quot;

animal_rescue &lt;- read_csv(url,
                          locale = locale(encoding = &quot;CP1252&quot;)) %&gt;% 
  janitor::clean_names()


glimpse(animal_rescue)</code></pre>
<pre><code>## Rows: 7,772
## Columns: 31
## $ incident_number               &lt;dbl&gt; 139091, 275091, 2075091, 2872091, 355309~
## $ date_time_of_call             &lt;chr&gt; &quot;01/01/2009 03:01&quot;, &quot;01/01/2009 08:51&quot;, ~
## $ cal_year                      &lt;dbl&gt; 2009, 2009, 2009, 2009, 2009, 2009, 2009~
## $ fin_year                      &lt;chr&gt; &quot;2008/09&quot;, &quot;2008/09&quot;, &quot;2008/09&quot;, &quot;2008/0~
## $ type_of_incident              &lt;chr&gt; &quot;Special Service&quot;, &quot;Special Service&quot;, &quot;S~
## $ pump_count                    &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, ~
## $ pump_hours_total              &lt;chr&gt; &quot;2&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, ~
## $ hourly_notional_cost          &lt;dbl&gt; 255, 255, 255, 255, 255, 255, 255, 255, ~
## $ incident_notional_cost        &lt;chr&gt; &quot;510&quot;, &quot;255&quot;, &quot;255&quot;, &quot;255&quot;, &quot;255&quot;, &quot;255&quot;~
## $ final_description             &lt;chr&gt; &quot;Redacted&quot;, &quot;Redacted&quot;, &quot;Redacted&quot;, &quot;Red~
## $ animal_group_parent           &lt;chr&gt; &quot;Dog&quot;, &quot;Fox&quot;, &quot;Dog&quot;, &quot;Horse&quot;, &quot;Rabbit&quot;, ~
## $ originof_call                 &lt;chr&gt; &quot;Person (land line)&quot;, &quot;Person (land line~
## $ property_type                 &lt;chr&gt; &quot;House - single occupancy&quot;, &quot;Railings&quot;, ~
## $ property_category             &lt;chr&gt; &quot;Dwelling&quot;, &quot;Outdoor Structure&quot;, &quot;Outdoo~
## $ special_service_type_category &lt;chr&gt; &quot;Other animal assistance&quot;, &quot;Other animal~
## $ special_service_type          &lt;chr&gt; &quot;Animal assistance involving livestock -~
## $ ward_code                     &lt;chr&gt; &quot;E05011467&quot;, &quot;E05000169&quot;, &quot;E05000558&quot;, &quot;~
## $ ward                          &lt;chr&gt; &quot;Crystal Palace &amp; Upper Norwood&quot;, &quot;Woods~
## $ borough_code                  &lt;chr&gt; &quot;E09000008&quot;, &quot;E09000008&quot;, &quot;E09000029&quot;, &quot;~
## $ borough                       &lt;chr&gt; &quot;Croydon&quot;, &quot;Croydon&quot;, &quot;Sutton&quot;, &quot;Hilling~
## $ stn_ground_name               &lt;chr&gt; &quot;Norbury&quot;, &quot;Woodside&quot;, &quot;Wallington&quot;, &quot;Ru~
## $ uprn                          &lt;chr&gt; &quot;NULL&quot;, &quot;NULL&quot;, &quot;NULL&quot;, &quot;100021491149&quot;, ~
## $ street                        &lt;chr&gt; &quot;Waddington Way&quot;, &quot;Grasmere Road&quot;, &quot;Mill~
## $ usrn                          &lt;chr&gt; &quot;20500146&quot;, &quot;NULL&quot;, &quot;NULL&quot;, &quot;21401484&quot;, ~
## $ postcode_district             &lt;chr&gt; &quot;SE19&quot;, &quot;SE25&quot;, &quot;SM5&quot;, &quot;UB9&quot;, &quot;RM3&quot;, &quot;RM~
## $ easting_m                     &lt;chr&gt; &quot;NULL&quot;, &quot;534785&quot;, &quot;528041&quot;, &quot;504689&quot;, &quot;N~
## $ northing_m                    &lt;chr&gt; &quot;NULL&quot;, &quot;167546&quot;, &quot;164923&quot;, &quot;190685&quot;, &quot;N~
## $ easting_rounded               &lt;dbl&gt; 532350, 534750, 528050, 504650, 554650, ~
## $ northing_rounded              &lt;dbl&gt; 170050, 167550, 164950, 190650, 192350, ~
## $ latitude                      &lt;chr&gt; &quot;NULL&quot;, &quot;51.39095371&quot;, &quot;51.36894086&quot;, &quot;5~
## $ longitude                     &lt;chr&gt; &quot;NULL&quot;, &quot;-0.064166887&quot;, &quot;-0.161985191&quot;, ~</code></pre>
<pre class="r"><code>animal_rescue %&gt;% 
  dplyr::group_by(cal_year) %&gt;% 
  summarise(count=n())</code></pre>
<pre><code>## # A tibble: 13 x 2
##    cal_year count
##       &lt;dbl&gt; &lt;int&gt;
##  1     2009   568
##  2     2010   611
##  3     2011   620
##  4     2012   603
##  5     2013   585
##  6     2014   583
##  7     2015   540
##  8     2016   604
##  9     2017   539
## 10     2018   610
## 11     2019   604
## 12     2020   758
## 13     2021   547</code></pre>
<pre class="r"><code>animal_rescue %&gt;% 
  count(cal_year, name=&quot;count&quot;)</code></pre>
<pre><code>## # A tibble: 13 x 2
##    cal_year count
##       &lt;dbl&gt; &lt;int&gt;
##  1     2009   568
##  2     2010   611
##  3     2011   620
##  4     2012   603
##  5     2013   585
##  6     2014   583
##  7     2015   540
##  8     2016   604
##  9     2017   539
## 10     2018   610
## 11     2019   604
## 12     2020   758
## 13     2021   547</code></pre>
<pre class="r"><code>animal_rescue %&gt;% 
  group_by(animal_group_parent) %&gt;% 
  
  #group_by and summarise will produce a new column with the count in each animal group
  summarise(count = n()) %&gt;% 
  
  # mutate adds a new column; here we calculate the percentage
  mutate(percent = round(100*count/sum(count),2)) %&gt;% 
  
  # arrange() sorts the data by percent. Since the default sorting is min to max and we would like to see it sorted
  # in descending order (max to min), we use arrange(desc()) 
  arrange(desc(percent))</code></pre>
<pre><code>## # A tibble: 28 x 3
##    animal_group_parent              count percent
##    &lt;chr&gt;                            &lt;int&gt;   &lt;dbl&gt;
##  1 Cat                               3736   48.1 
##  2 Bird                              1611   20.7 
##  3 Dog                               1213   15.6 
##  4 Fox                                366    4.71
##  5 Unknown - Domestic Animal Or Pet   199    2.56
##  6 Horse                              195    2.51
##  7 Deer                               132    1.7 
##  8 Unknown - Wild Animal               93    1.2 
##  9 Squirrel                            66    0.85
## 10 Unknown - Heavy Livestock Animal    50    0.64
## # ... with 18 more rows</code></pre>
<pre class="r"><code>animal_rescue %&gt;% 
  
  #count does the same thing as group_by and summarise
  # name = &quot;count&quot; will call the column with the counts &quot;count&quot; ( exciting, I know)
  # and &#39;sort=TRUE&#39; will sort them from max to min
  count(animal_group_parent, name=&quot;count&quot;, sort=TRUE) %&gt;% 
  mutate(percent = round(100*count/sum(count),2))</code></pre>
<pre><code>## # A tibble: 28 x 3
##    animal_group_parent              count percent
##    &lt;chr&gt;                            &lt;int&gt;   &lt;dbl&gt;
##  1 Cat                               3736   48.1 
##  2 Bird                              1611   20.7 
##  3 Dog                               1213   15.6 
##  4 Fox                                366    4.71
##  5 Unknown - Domestic Animal Or Pet   199    2.56
##  6 Horse                              195    2.51
##  7 Deer                               132    1.7 
##  8 Unknown - Wild Animal               93    1.2 
##  9 Squirrel                            66    0.85
## 10 Unknown - Heavy Livestock Animal    50    0.64
## # ... with 18 more rows</code></pre>
<blockquote>
<p>Please note that any cost included is a notional cost calculated based on the length of time rounded up to the nearest hour spent by Pump, Aerial and FRU appliances at the incident and charged at the current Brigade hourly rate.</p>
</blockquote>
<pre class="r"><code># what type is variable incident_notional_cost from dataframe `animal_rescue`
typeof(animal_rescue$incident_notional_cost)</code></pre>
<pre><code>## [1] &quot;character&quot;</code></pre>
<pre class="r"><code># readr::parse_number() will convert any numerical values stored as characters into numbers
animal_rescue &lt;- animal_rescue %&gt;% 

  # we use mutate() to use the parse_number() function and overwrite the same variable
  mutate(incident_notional_cost = parse_number(incident_notional_cost))

# incident_notional_cost from dataframe `animal_rescue` is now &#39;double&#39; or numeric
typeof(animal_rescue$incident_notional_cost)</code></pre>
<pre><code>## [1] &quot;double&quot;</code></pre>
<pre class="r"><code>animal_rescue %&gt;% 
  
  # group by animal_group_parent
  group_by(animal_group_parent) %&gt;% 
  
  # filter resulting data, so each group has at least 6 observations
  filter(n()&gt;6) %&gt;% 
  
  # summarise() will collapse all values into 3 values: the mean, median, and count  
  # we use na.rm=TRUE to make sure we remove any NAs, or cases where we do not have the incident cos
  summarise(mean_incident_cost = mean (incident_notional_cost, na.rm=TRUE),
            median_incident_cost = median (incident_notional_cost, na.rm=TRUE),
            sd_incident_cost = sd (incident_notional_cost, na.rm=TRUE),
            min_incident_cost = min (incident_notional_cost, na.rm=TRUE),
            max_incident_cost = max (incident_notional_cost, na.rm=TRUE),
            count = n()) %&gt;% 
  
  # sort the resulting data in descending order. You choose whether to sort by count or mean cost.
  arrange(desc(mean_incident_cost))</code></pre>
<pre><code>## # A tibble: 16 x 7
##    animal_group_parent      mean_incident_co~ median_incident_~ sd_incident_cost
##    &lt;chr&gt;                                &lt;dbl&gt;             &lt;dbl&gt;            &lt;dbl&gt;
##  1 Horse                                 740.               596            541. 
##  2 Cow                                   634.               520            475. 
##  3 Deer                                  417.               333            286. 
##  4 Unknown - Wild Animal                 416.               333            324. 
##  5 Unknown - Heavy Livesto~              374.               260            263. 
##  6 Fox                                   373.               328            206. 
##  7 Snake                                 356.               339            105. 
##  8 Dog                                   347.               298            169. 
##  9 Bird                                  344.               328            135. 
## 10 Cat                                   343.               298            160. 
## 11 Unknown - Domestic Anim~              326.               295            117. 
## 12 cat                                   324.               290             94.1
## 13 Hamster                               315.               290             95.0
## 14 Squirrel                              313.               326             57.1
## 15 Ferret                                309.               333             39.4
## 16 Rabbit                                309.               326             32.2
## # ... with 3 more variables: min_incident_cost &lt;dbl&gt;, max_incident_cost &lt;dbl&gt;,
## #   count &lt;int&gt;</code></pre>
<p>From the comparison of the mean and median of each group, we can see that the incident cost for Horse is relatively higher than other animal groups. The cost for cat is relatively lower instead.<br />
Among all the animal groups, we found an outlier in dogs group with the minimum incident cost of 0, which lowers down the mean incident cost for the dog group.</p>
<pre class="r"><code># base_plot
base_plot &lt;- animal_rescue %&gt;% 
  group_by(animal_group_parent) %&gt;% 
  filter(n()&gt;6) %&gt;% 
  ggplot(aes(x=incident_notional_cost))+
  facet_wrap(~animal_group_parent, scales = &quot;free&quot;)+
  theme_bw()

base_plot + geom_histogram()</code></pre>
<p><img src="/blogs/Hanlu%20Lin_files/figure-html/plots_on_incident_cost_by_animal_group-1.png" width="672" /></p>
<pre class="r"><code>base_plot + geom_density()</code></pre>
<p><img src="/blogs/Hanlu%20Lin_files/figure-html/plots_on_incident_cost_by_animal_group-2.png" width="672" /></p>
<pre class="r"><code>base_plot + geom_boxplot()</code></pre>
<p><img src="/blogs/Hanlu%20Lin_files/figure-html/plots_on_incident_cost_by_animal_group-3.png" width="672" /></p>
<pre class="r"><code>base_plot + stat_ecdf(geom = &quot;step&quot;, pad = FALSE) +
  scale_y_continuous(labels = scales::percent)</code></pre>
<p><img src="/blogs/Hanlu%20Lin_files/figure-html/plots_on_incident_cost_by_animal_group-4.png" width="672" /></p>
<p>I think the distribution histogram best communicates the variability of the <code>incident_notional_cost</code> values, as we can see clearly how it distributes from the graph.<br />
From the graph, we can tell that horses are more expensive to rescue than other animals. The cost of most cases of horses is around 1000, and some of the cases indicates costs around 2000-3000. While other animals like rabbit, hamster, squirrel, ferret, and cat, the incident cost of these animal groups are more centered in the range of 200-400, which is relatively lower. These animals are cheaper to rescue instead.</p>
<div id="details" class="section level2">
<h2>Details</h2>
<p>If you want to, please answer the following</p>
<ul>
<li>Who did you collaborate with: By myself.</li>
<li>Approximately how much time did you spend on this problem set: half an hour.</li>
<li>What, if anything, gave you the most trouble: So far so good.</li>
</ul>
</div>
</div>
